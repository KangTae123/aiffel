{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# digits image classification\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits \n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "print(digits.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "data shape : (1797, 64)\n",
      "label shape (1797,)\n",
      "label velue :  [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "digits_data = digits.data\n",
    "digits_label = digits.target\n",
    "\n",
    "print(type(digits_data))\n",
    "print('data shape :', digits_data.shape)\n",
    "print('label shape', digits_label.shape)\n",
    "print('label velue : ', digits.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### digits dataset은 8x8(64)의 pixel을 가진 1797개 image이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1437, 64)\n",
      "(360, 64)\n",
      "(1437,)\n",
      "(360,)\n"
     ]
    }
   ],
   "source": [
    "# data를 training data 와 test data로 split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_data, digits_label, test_size=0.2, random_state=7)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision_tree accuracy score :  0.8555555555555555\n",
      "RandomForestClassifier accuracy score :  0.9638888888888889\n",
      "Supprot Vector Machine accuracy score :  0.9888888888888889\n",
      "Stochastic Gradient Descent Classifier accuracy score :  0.9416666666666667\n",
      "LogisticRegression accuracy score :  0.9527777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# dscision tree model training, prediction\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print('decision_tree accuracy score : ', accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# random forest model training, prediction\n",
    "rf = RandomForestClassifier(random_state=32)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print('RandomForestClassifier accuracy score : ', accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Supprot Vector Machine model training, prediction\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "print('Supprot Vector Machine accuracy score : ', accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Stochastic Gradient Descent Classifier model training, prediction\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, y_train)\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print('Stochastic Gradient Descent Classifier accuracy score : ', accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# LogisticRegression model training, prediction\n",
    "LR = LogisticRegression(max_iter=10000)\n",
    "LR.fit(X_train, y_train)\n",
    "y_pred = LR.predict(X_test)\n",
    "\n",
    "print('LogisticRegression accuracy score : ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 해당 data에 최고 성능을 찾는 model을 학습하는 것이 주 목적이 아니기에\n",
    "#### 모든 model의 hyperparameter 는 default 값으로 학습하였고\\\n",
    "#### 이때 predict accuracy가 가장 높은 model은 SVM이었다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predict data 를 다시 svm으로 뽑아준다\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[43,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 42,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0, 40,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 34,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 37,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 28,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0, 28,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 33,  0,  0],\n",
       "       [ 0,  2,  0,  0,  0,  1,  0,  0, 40,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1,  0,  0,  0, 31]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사실 label별 중요도가 존재하지 않는 multi label dataset 이기에\n",
    "#### confusion matrix를 통한 평가지표는 큰 의미가 없다고 생각하지만\n",
    "#### confusion matrix를 살펴보았을때 \n",
    "#### 8 의 recall값이 가장 낮았고 (8을 다른 숫자로 예측할 확률이 높은 것)\n",
    "#### 5 의 precision값이 가장 낮았다 (다른 숫자를 5로 예측할 확률이 높은 것)\n",
    "#### 아래와같이 표를통해 확인 할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      1.00      0.98        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        33\n",
      "           8       1.00      0.93      0.96        43\n",
      "           9       1.00      0.97      0.98        32\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wine dataset classicication\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()\n",
    "\n",
    "wine_data = wine.data\n",
    "wine_label = wine.target\n",
    "\n",
    "wine.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n",
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "print(wine_data.shape)\n",
    "print(wine.feature_names)\n",
    "print(wine.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 13 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   alcohol                       178 non-null    float64\n",
      " 1   malic_acid                    178 non-null    float64\n",
      " 2   ash                           178 non-null    float64\n",
      " 3   alcalinity_of_ash             178 non-null    float64\n",
      " 4   magnesium                     178 non-null    float64\n",
      " 5   total_phenols                 178 non-null    float64\n",
      " 6   flavanoids                    178 non-null    float64\n",
      " 7   nonflavanoid_phenols          178 non-null    float64\n",
      " 8   proanthocyanins               178 non-null    float64\n",
      " 9   color_intensity               178 non-null    float64\n",
      " 10  hue                           178 non-null    float64\n",
      " 11  od280/od315_of_diluted_wines  178 non-null    float64\n",
      " 12  proline                       178 non-null    float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 18.2 KB\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import pandas as pd\n",
    "\n",
    "df_wine = pd.DataFrame(data = wine_data, columns=wine.feature_names)\n",
    "\n",
    "df_wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alcohol  :\n",
      "12.37    6\n",
      "13.05    6\n",
      "12.08    5\n",
      "12.29    4\n",
      "12.00    3\n",
      "        ..\n",
      "13.34    1\n",
      "13.69    1\n",
      "13.90    1\n",
      "13.84    1\n",
      "13.75    1\n",
      "Name: alcohol, Length: 126, dtype: int64 \n",
      "\n",
      "malic_acid  :\n",
      "1.73    7\n",
      "1.81    4\n",
      "1.67    4\n",
      "1.68    3\n",
      "1.61    3\n",
      "       ..\n",
      "3.45    1\n",
      "2.51    1\n",
      "4.61    1\n",
      "3.83    1\n",
      "2.68    1\n",
      "Name: malic_acid, Length: 133, dtype: int64 \n",
      "\n",
      "ash  :\n",
      "2.30    7\n",
      "2.28    7\n",
      "2.70    6\n",
      "2.36    6\n",
      "2.32    6\n",
      "       ..\n",
      "2.16    1\n",
      "2.78    1\n",
      "2.53    1\n",
      "1.71    1\n",
      "1.95    1\n",
      "Name: ash, Length: 79, dtype: int64 \n",
      "\n",
      "alcalinity_of_ash  :\n",
      "20.0    15\n",
      "21.0    11\n",
      "16.0    11\n",
      "18.0    10\n",
      "19.0     9\n",
      "        ..\n",
      "19.4     1\n",
      "11.2     1\n",
      "21.6     1\n",
      "18.1     1\n",
      "14.8     1\n",
      "Name: alcalinity_of_ash, Length: 63, dtype: int64 \n",
      "\n",
      "magnesium  :\n",
      "88.0     13\n",
      "86.0     11\n",
      "98.0      9\n",
      "101.0     9\n",
      "96.0      8\n",
      "102.0     7\n",
      "112.0     6\n",
      "85.0      6\n",
      "94.0      6\n",
      "80.0      5\n",
      "92.0      5\n",
      "89.0      5\n",
      "97.0      5\n",
      "103.0     5\n",
      "107.0     4\n",
      "106.0     4\n",
      "90.0      4\n",
      "108.0     4\n",
      "104.0     3\n",
      "111.0     3\n",
      "78.0      3\n",
      "116.0     3\n",
      "95.0      3\n",
      "120.0     3\n",
      "110.0     3\n",
      "100.0     3\n",
      "87.0      3\n",
      "84.0      3\n",
      "118.0     3\n",
      "93.0      2\n",
      "115.0     2\n",
      "113.0     2\n",
      "91.0      2\n",
      "105.0     2\n",
      "121.0     1\n",
      "123.0     1\n",
      "132.0     1\n",
      "126.0     1\n",
      "124.0     1\n",
      "122.0     1\n",
      "128.0     1\n",
      "117.0     1\n",
      "151.0     1\n",
      "139.0     1\n",
      "136.0     1\n",
      "99.0      1\n",
      "70.0      1\n",
      "81.0      1\n",
      "162.0     1\n",
      "134.0     1\n",
      "119.0     1\n",
      "82.0      1\n",
      "127.0     1\n",
      "Name: magnesium, dtype: int64 \n",
      "\n",
      "total_phenols  :\n",
      "2.20    8\n",
      "3.00    6\n",
      "2.80    6\n",
      "2.60    6\n",
      "2.00    5\n",
      "       ..\n",
      "2.90    1\n",
      "2.02    1\n",
      "3.27    1\n",
      "2.83    1\n",
      "1.93    1\n",
      "Name: total_phenols, Length: 97, dtype: int64 \n",
      "\n",
      "flavanoids  :\n",
      "2.65    4\n",
      "0.58    3\n",
      "2.68    3\n",
      "0.60    3\n",
      "1.25    3\n",
      "       ..\n",
      "2.78    1\n",
      "1.02    1\n",
      "1.30    1\n",
      "2.90    1\n",
      "3.25    1\n",
      "Name: flavanoids, Length: 132, dtype: int64 \n",
      "\n",
      "nonflavanoid_phenols  :\n",
      "0.26    11\n",
      "0.43    11\n",
      "0.29    10\n",
      "0.32     9\n",
      "0.30     8\n",
      "0.37     8\n",
      "0.34     8\n",
      "0.27     8\n",
      "0.40     8\n",
      "0.24     7\n",
      "0.53     7\n",
      "0.21     6\n",
      "0.22     6\n",
      "0.28     5\n",
      "0.39     5\n",
      "0.17     5\n",
      "0.50     5\n",
      "0.52     5\n",
      "0.47     4\n",
      "0.42     4\n",
      "0.48     4\n",
      "0.63     4\n",
      "0.58     3\n",
      "0.60     3\n",
      "0.45     3\n",
      "0.61     3\n",
      "0.14     2\n",
      "0.19     2\n",
      "0.25     2\n",
      "0.20     2\n",
      "0.31     2\n",
      "0.55     1\n",
      "0.41     1\n",
      "0.66     1\n",
      "0.56     1\n",
      "0.13     1\n",
      "0.44     1\n",
      "0.33     1\n",
      "0.35     1\n",
      "Name: nonflavanoid_phenols, dtype: int64 \n",
      "\n",
      "proanthocyanins  :\n",
      "1.35    9\n",
      "1.46    7\n",
      "1.87    6\n",
      "1.25    5\n",
      "1.56    4\n",
      "       ..\n",
      "1.53    1\n",
      "0.68    1\n",
      "1.72    1\n",
      "1.71    1\n",
      "0.88    1\n",
      "Name: proanthocyanins, Length: 101, dtype: int64 \n",
      "\n",
      "color_intensity  :\n",
      "2.60    4\n",
      "4.60    4\n",
      "3.80    4\n",
      "3.40    3\n",
      "3.05    3\n",
      "       ..\n",
      "3.21    1\n",
      "6.90    1\n",
      "7.80    1\n",
      "5.20    1\n",
      "6.75    1\n",
      "Name: color_intensity, Length: 132, dtype: int64 \n",
      "\n",
      "hue  :\n",
      "1.04    8\n",
      "1.23    7\n",
      "1.12    6\n",
      "0.89    5\n",
      "0.57    5\n",
      "       ..\n",
      "1.17    1\n",
      "0.55    1\n",
      "0.76    1\n",
      "1.22    1\n",
      "0.69    1\n",
      "Name: hue, Length: 78, dtype: int64 \n",
      "\n",
      "od280/od315_of_diluted_wines  :\n",
      "2.87    5\n",
      "3.00    4\n",
      "1.82    4\n",
      "2.78    4\n",
      "2.77    3\n",
      "       ..\n",
      "3.31    1\n",
      "3.69    1\n",
      "2.01    1\n",
      "1.96    1\n",
      "2.73    1\n",
      "Name: od280/od315_of_diluted_wines, Length: 122, dtype: int64 \n",
      "\n",
      "proline  :\n",
      "680.0     5\n",
      "520.0     5\n",
      "750.0     4\n",
      "630.0     4\n",
      "625.0     4\n",
      "         ..\n",
      "342.0     1\n",
      "1375.0    1\n",
      "530.0     1\n",
      "720.0     1\n",
      "385.0     1\n",
      "Name: proline, Length: 121, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_wine.columns)):\n",
    "    print(df_wine.columns[i], \" :\")\n",
    "    print(df_wine.iloc[:,i].value_counts(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature name 을 살펴보니 13개의 feature 는 wine의 성분들을 뜻하는 듯 하다\n",
    "#### 전부 수치데이터라 뭐가뭔진 잘 모르겠다\n",
    "#### 해당 dataset은 3개의 label을 가지고있으며 178개의 data를 가지고있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 13)\n",
      "(36, 13)\n",
      "(142,)\n",
      "(36,)\n"
     ]
    }
   ],
   "source": [
    "# data를 training data 와 test data로 split\n",
    "\n",
    "wine_X_train, wine_X_test, wine_y_train, wine_y_test = train_test_split(wine_data, wine_label, test_size=0.2, random_state=7)\n",
    "\n",
    "print(wine_X_train.shape)\n",
    "print(wine_X_test.shape)\n",
    "print(wine_y_train.shape)\n",
    "print(wine_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision_tree accuracy score :  0.9444444444444444\n",
      "RandomForestClassifier accuracy score :  1.0\n",
      "Supprot Vector Machine accuracy score :  0.9444444444444444\n",
      "Stochastic Gradient Descent Classifier accuracy score :  0.5277777777777778\n",
      "LogisticRegression accuracy score :  0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "# dscision tree model training, prediction\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(wine_X_train, wine_y_train)\n",
    "wine_y_pred = decision_tree.predict(wine_X_test)\n",
    "\n",
    "print('decision_tree accuracy score : ', accuracy_score(wine_y_test, wine_y_pred))\n",
    "\n",
    "\n",
    "# RandomForest model training, prediction\n",
    "rf = RandomForestClassifier(random_state=8)\n",
    "rf.fit(wine_X_train, wine_y_train)\n",
    "wine_y_pred = rf.predict(wine_X_test)\n",
    "\n",
    "print('RandomForestClassifier accuracy score : ', accuracy_score(wine_y_test, wine_y_pred))\n",
    "\n",
    "\n",
    "# dscision tree model training, prediction\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(wine_X_train, wine_y_train)\n",
    "wine_y_pred = svm.predict(wine_X_test)\n",
    "\n",
    "print('Supprot Vector Machine accuracy score : ', accuracy_score(wine_y_test, wine_y_pred))\n",
    "\n",
    "\n",
    "# SGD model training, prediction\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(wine_X_train, wine_y_train)\n",
    "wine_y_pred = sgd.predict(wine_X_test)\n",
    "\n",
    "print('Stochastic Gradient Descent Classifier accuracy score : ', accuracy_score(wine_y_test, wine_y_pred))\n",
    "\n",
    "\n",
    "# LogisticRegression model training, prediction\n",
    "LR = LogisticRegression(max_iter=10000)\n",
    "LR.fit(wine_X_train, wine_y_train)\n",
    "wine_y_pred = LR.predict(wine_X_test)\n",
    "\n",
    "print('LogisticRegression accuracy score : ', accuracy_score(wine_y_test, wine_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 해당 dataset은 Decision Tree, Random Forest, Logistic Regression 에 대하여 높은 예측을 보였고 SGD는 낮은 성능을 보인다, SVM은 디폴트 파라미터에선 낮은 성능을 보였지만 파라미터인 kernel을 linear로 설정하여 성능을 높혔다.\n",
    "#### Logistic Regression model을 사용한 예측은 다음과같은 지표를 보인다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      1.00      0.97        17\n",
      "           2       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.97      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(wine_y_test, wine_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# breast cancer data classification\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "cancer_data = cancer.data\n",
    "cancer_label = cancer.target\n",
    "\n",
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "print(cancer_data.shape)\n",
    "print(cancer.feature_names)\n",
    "print(cancer.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cancer dataset은 30개의 feature를 갖고있는 569개의 dataset이다\n",
    "#### malignant(악성)과 benign(양성) 의 label을 갖은 binary classification 문제다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30)\n",
      "(114, 30)\n",
      "(455,)\n",
      "(114,)\n"
     ]
    }
   ],
   "source": [
    "cancer_X_train, cancer_X_test, cancer_y_train, cancer_y_test = train_test_split(cancer_data, cancer_label, test_size=0.2, random_state=7)\n",
    "\n",
    "print(cancer_X_train.shape)\n",
    "print(cancer_X_test.shape)\n",
    "print(cancer_y_train.shape)\n",
    "print(cancer_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision_tree accuracy score :  0.9122807017543859\n",
      "RandomForestClassifier accuracy score :  1.0\n",
      "Supprot Vector Machine accuracy score :  0.9473684210526315\n",
      "Stochastic Gradient Descent Classifier accuracy score :  0.8245614035087719\n",
      "LogisticRegression accuracy score :  0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(cancer_X_train, cancer_y_train)\n",
    "cancer_y_pred = decision_tree.predict(cancer_X_test)\n",
    "\n",
    "print('decision_tree accuracy score : ', accuracy_score(cancer_y_test, cancer_y_pred))\n",
    "\n",
    "rf = RandomForestClassifier(random_state=32)\n",
    "rf.fit(cancer_X_train, cancer_y_train)\n",
    "cancer_y_pred = rf.predict(cancer_X_test)\n",
    "\n",
    "print('RandomForestClassifier accuracy score : ', accuracy_score(cancer_y_test, cancer_y_pred))\n",
    "\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(cancer_X_train, cancer_y_train)\n",
    "cancer_y_pred = svm.predict(cancer_X_test)\n",
    "\n",
    "print('Supprot Vector Machine accuracy score : ', accuracy_score(cancer_y_test, cancer_y_pred))\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(cancer_X_train, cancer_y_train)\n",
    "cancer_y_pred = sgd.predict(cancer_X_test)\n",
    "\n",
    "print('Stochastic Gradient Descent Classifier accuracy score : ', accuracy_score(cancer_y_test, cancer_y_pred))\n",
    "\n",
    "LR = LogisticRegression(max_iter=10000)\n",
    "LR.fit(cancer_X_train, cancer_y_train)\n",
    "cancer_y_pred = LR.predict(cancer_X_test)\n",
    "\n",
    "print('LogisticRegression accuracy score : ', accuracy_score(cancer_y_test, cancer_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 해당 dataset은 대부분의 모델에서 좋은 성능을 보였으며\n",
    "#### RandomForestClassifier 모델이 완벽한 성능을 보였다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
